{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIHyeeM7Np8_",
        "outputId": "6da4ab47-1bc5-4e67-e948-ea71f695eccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path =\"/content/drive/MyDrive/Colab Notebooks/Data/job_intents.json\""
      ],
      "metadata": {
        "id": "DM2O6jt4OKDf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Environment + imports + Colab-safe drive mount\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "2llnJcRqOkcH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-safe drive mount: attempt to mount if running on Colab, otherwise use cwd\n",
        "try:\n",
        "    import google.colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_base_path = '/content/drive/MyDrive/Colab Notebooks/Data'\n",
        "    print(\"Running on Colab. Using data_base_path =\", data_base_path)\n",
        "except Exception:\n",
        "    data_base_path = os.getcwd()\n",
        "    print(\"Not running on Colab. Using current working directory as data_base_path =\", data_base_path)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmXR1z5sOnUE",
        "outputId": "69b61e8a-2524-47c0-e29c-18ab43aaff7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Running on Colab. Using data_base_path = /content/drive/MyDrive/Colab Notebooks/Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: data path and NLTK downloads\n",
        "data_path = os.path.join(data_base_path, 'job_intents.json')\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    raise FileNotFoundError(f\"Data file not found at: {data_path}\\nPlease place job_intents.json in {data_base_path}\")\n",
        "\n",
        "# NLTK resources (download if needed)\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj2KnGEsOvgK",
        "outputId": "e800b5ef-365f-4a15-835e-f5ba3c169260"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: load JSON intents\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    intents = json.load(f)\n",
        ""
      ],
      "metadata": {
        "id": "7hamqBPNOvck"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkcY-h-WOvaE",
        "outputId": "b6212bf0-194f-4ff6-de10-e53874a07248"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "ignore_words = ['?', '!', '.', ',']\n",
        "\n",
        "words = []       # all unique words (raw tokens, will lemmatize later)\n",
        "classes = []     # unique intent tags\n",
        "documents = []   # list of (tokenized_pattern, tag) tuples\n",
        "\n",
        "for intent in intents.get('intents', []):\n",
        "    tag = intent.get('tag')\n",
        "    for pattern in intent.get('patterns', []):\n",
        "        tokens = word_tokenize(pattern)\n",
        "        words.extend(tokens)\n",
        "        documents.append((tokens, tag))\n",
        "    if tag not in classes:\n",
        "        classes.append(tag)\n",
        "\n",
        "# Lemmatize and lower-case words, remove ignored tokens, deduplicate & sort\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))\n",
        "\n",
        "print(\"Total unique words:\", len(words))\n",
        "print(\"Total classes:\", len(classes))\n",
        "print(\"Total documents:\", len(documents))\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-LbxAV_OvXY",
        "outputId": "caacb54c-7503-4828-bc7f-f99dec0cafec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words: 100\n",
            "Total classes: 20\n",
            "Total documents: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: create bag-of-words vector function and build training set\n",
        "def bag_of_words(tokenized_sentence, all_words):\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in tokenized_sentence]\n",
        "    bag = [1 if w in sentence_words else 0 for w in all_words]\n",
        "    return np.array(bag, dtype=int)\n",
        "\n",
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for doc in documents:\n",
        "    pattern_tokens = doc[0]\n",
        "    tag = doc[1]\n",
        "    bag = bag_of_words(pattern_tokens, words)\n",
        "    output_row = output_empty.copy()\n",
        "    output_row[classes.index(tag)] = 1\n",
        "    training.append([bag, output_row])\n",
        "\n"
      ],
      "metadata": {
        "id": "dscpnih1OvUM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: shuffle and split into train_x, train_y\n",
        "random.shuffle(training)\n",
        "\n",
        "# --- FIX: use list comprehensions to extract columns (works independent of numpy shape) ---\n",
        "train_x = [t[0] for t in training]\n",
        "train_y = [t[1] for t in training]\n",
        "\n",
        "train_x = np.array(train_x, dtype=float)\n",
        "train_y = np.array(train_y, dtype=float)\n",
        "\n",
        "print(\"train_x shape:\", train_x.shape)\n",
        "print(\"train_y shape:\", train_y.shape)\n",
        "\n",
        "VALIDATION_SET = (train_x, train_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2RI7xOAOvRn",
        "outputId": "0de2d55d-6cb7-481a-d64d-adb70e2b227e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x shape: (67, 100)\n",
            "train_y shape: (67, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create a simple feed-forward network\n",
        "input_size = train_x.shape[1]\n",
        "output_size = train_y.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(input_size,), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(output_size, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "GfSWOJ1VOvPE",
        "outputId": "37d6687c-60dc-4f96-b943-83d60e602196"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m1,300\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,484\u001b[0m (87.83 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,484</span> (87.83 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,484\u001b[0m (87.83 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,484</span> (87.83 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Compile the model\n",
        "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "snyjQBEJOvMg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Train\n",
        "history = model.fit(\n",
        "    train_x,\n",
        "    train_y,\n",
        "    epochs=250,\n",
        "    batch_size=5,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYFW7yNUOvKD",
        "outputId": "675b0588-8976-43c9-a8e8-de953bbeb8ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.0424 - loss: 3.0261 - val_accuracy: 0.0000e+00 - val_loss: 3.0211\n",
            "Epoch 2/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0111 - loss: 3.0209 - val_accuracy: 0.0000e+00 - val_loss: 3.0718\n",
            "Epoch 3/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1666 - loss: 2.9134 - val_accuracy: 0.0714 - val_loss: 3.1193\n",
            "Epoch 4/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1603 - loss: 2.7835 - val_accuracy: 0.0714 - val_loss: 3.1777\n",
            "Epoch 5/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3019 - loss: 2.6639 - val_accuracy: 0.0714 - val_loss: 3.2333\n",
            "Epoch 6/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2500 - loss: 2.6604 - val_accuracy: 0.0714 - val_loss: 3.2782\n",
            "Epoch 7/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1965 - loss: 2.5632 - val_accuracy: 0.0714 - val_loss: 3.2981\n",
            "Epoch 8/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3511 - loss: 2.4572 - val_accuracy: 0.0714 - val_loss: 3.3462\n",
            "Epoch 9/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3253 - loss: 2.3477 - val_accuracy: 0.0714 - val_loss: 3.3744\n",
            "Epoch 10/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4288 - loss: 2.2405 - val_accuracy: 0.0714 - val_loss: 3.3298\n",
            "Epoch 11/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3794 - loss: 2.1663 - val_accuracy: 0.0714 - val_loss: 3.3348\n",
            "Epoch 12/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4811 - loss: 2.1427 - val_accuracy: 0.0714 - val_loss: 3.3535\n",
            "Epoch 13/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5019 - loss: 1.7500 - val_accuracy: 0.0714 - val_loss: 3.3445\n",
            "Epoch 14/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4308 - loss: 1.7516 - val_accuracy: 0.0714 - val_loss: 3.2809\n",
            "Epoch 15/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6226 - loss: 1.6083 - val_accuracy: 0.1429 - val_loss: 3.2788\n",
            "Epoch 16/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6053 - loss: 1.4879 - val_accuracy: 0.1429 - val_loss: 3.1916\n",
            "Epoch 17/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5972 - loss: 1.4261 - val_accuracy: 0.1429 - val_loss: 3.1796\n",
            "Epoch 18/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6840 - loss: 1.2687 - val_accuracy: 0.1429 - val_loss: 3.1699\n",
            "Epoch 19/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6733 - loss: 1.3121 - val_accuracy: 0.1429 - val_loss: 3.1341\n",
            "Epoch 20/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7958 - loss: 1.0911 - val_accuracy: 0.2143 - val_loss: 3.0793\n",
            "Epoch 21/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8285 - loss: 0.9816 - val_accuracy: 0.2143 - val_loss: 3.1500\n",
            "Epoch 22/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6662 - loss: 1.1938 - val_accuracy: 0.2143 - val_loss: 3.0820\n",
            "Epoch 23/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7246 - loss: 0.8611 - val_accuracy: 0.2143 - val_loss: 3.0949\n",
            "Epoch 24/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7500 - loss: 1.0030 - val_accuracy: 0.2857 - val_loss: 3.0801\n",
            "Epoch 25/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.7815 - val_accuracy: 0.2143 - val_loss: 3.0316\n",
            "Epoch 26/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.6384 - val_accuracy: 0.2143 - val_loss: 3.0046\n",
            "Epoch 27/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7177 - loss: 0.9405 - val_accuracy: 0.2857 - val_loss: 2.9960\n",
            "Epoch 28/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8653 - loss: 0.6082 - val_accuracy: 0.2143 - val_loss: 2.9519\n",
            "Epoch 29/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7754 - loss: 0.6742 - val_accuracy: 0.2857 - val_loss: 3.1075\n",
            "Epoch 30/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.5266 - val_accuracy: 0.2857 - val_loss: 3.1152\n",
            "Epoch 31/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7599 - loss: 0.7364 - val_accuracy: 0.2857 - val_loss: 3.0345\n",
            "Epoch 32/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.4500 - val_accuracy: 0.2143 - val_loss: 3.0630\n",
            "Epoch 33/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8627 - loss: 0.4409 - val_accuracy: 0.2143 - val_loss: 3.0307\n",
            "Epoch 34/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7984 - loss: 0.6028 - val_accuracy: 0.2857 - val_loss: 2.9935\n",
            "Epoch 35/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8504 - loss: 0.6181 - val_accuracy: 0.2857 - val_loss: 2.9015\n",
            "Epoch 36/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.4762 - val_accuracy: 0.2857 - val_loss: 2.7723\n",
            "Epoch 37/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8156 - loss: 0.4804 - val_accuracy: 0.2857 - val_loss: 2.8898\n",
            "Epoch 38/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8535 - loss: 0.4650 - val_accuracy: 0.2857 - val_loss: 3.0820\n",
            "Epoch 39/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8614 - loss: 0.5006 - val_accuracy: 0.2857 - val_loss: 2.9807\n",
            "Epoch 40/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8445 - loss: 0.5297 - val_accuracy: 0.2857 - val_loss: 2.9565\n",
            "Epoch 41/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9210 - loss: 0.3706 - val_accuracy: 0.2857 - val_loss: 2.9801\n",
            "Epoch 42/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9437 - loss: 0.3348 - val_accuracy: 0.2857 - val_loss: 2.9120\n",
            "Epoch 43/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9022 - loss: 0.3271 - val_accuracy: 0.2857 - val_loss: 2.9702\n",
            "Epoch 44/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.2637 - val_accuracy: 0.2857 - val_loss: 3.0121\n",
            "Epoch 45/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8910 - loss: 0.4620 - val_accuracy: 0.3571 - val_loss: 2.9186\n",
            "Epoch 46/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.2774 - val_accuracy: 0.3571 - val_loss: 2.9146\n",
            "Epoch 47/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9083 - loss: 0.2235 - val_accuracy: 0.3571 - val_loss: 2.9559\n",
            "Epoch 48/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.3165 - val_accuracy: 0.2857 - val_loss: 2.9269\n",
            "Epoch 49/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8102 - loss: 0.4226 - val_accuracy: 0.2857 - val_loss: 2.8504\n",
            "Epoch 50/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9096 - loss: 0.2984 - val_accuracy: 0.2857 - val_loss: 2.9254\n",
            "Epoch 51/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9497 - loss: 0.2541 - val_accuracy: 0.2857 - val_loss: 2.9254\n",
            "Epoch 52/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.1170 - val_accuracy: 0.2857 - val_loss: 2.9286\n",
            "Epoch 53/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.1792 - val_accuracy: 0.2857 - val_loss: 2.9038\n",
            "Epoch 54/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9420 - loss: 0.2002 - val_accuracy: 0.2857 - val_loss: 2.9470\n",
            "Epoch 55/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.1197 - val_accuracy: 0.2857 - val_loss: 2.9351\n",
            "Epoch 56/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8629 - loss: 0.3117 - val_accuracy: 0.2857 - val_loss: 3.0939\n",
            "Epoch 57/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9361 - loss: 0.2188 - val_accuracy: 0.2857 - val_loss: 3.0657\n",
            "Epoch 58/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1818 - val_accuracy: 0.3571 - val_loss: 2.9775\n",
            "Epoch 59/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.2895 - val_accuracy: 0.3571 - val_loss: 2.9637\n",
            "Epoch 60/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8653 - loss: 0.2919 - val_accuracy: 0.3571 - val_loss: 2.8760\n",
            "Epoch 61/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9163 - loss: 0.2245 - val_accuracy: 0.3571 - val_loss: 2.8783\n",
            "Epoch 62/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.2166 - val_accuracy: 0.3571 - val_loss: 2.9836\n",
            "Epoch 63/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9038 - loss: 0.2058 - val_accuracy: 0.2857 - val_loss: 3.1794\n",
            "Epoch 64/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9410 - loss: 0.1986 - val_accuracy: 0.2857 - val_loss: 3.2048\n",
            "Epoch 65/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9657 - loss: 0.1944 - val_accuracy: 0.2857 - val_loss: 3.0726\n",
            "Epoch 66/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9441 - loss: 0.1919 - val_accuracy: 0.3571 - val_loss: 2.9467\n",
            "Epoch 67/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9130 - loss: 0.3258 - val_accuracy: 0.3571 - val_loss: 2.8531\n",
            "Epoch 68/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.1386 - val_accuracy: 0.3571 - val_loss: 2.7706\n",
            "Epoch 69/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9780 - loss: 0.1652 - val_accuracy: 0.3571 - val_loss: 2.6711\n",
            "Epoch 70/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1135 - val_accuracy: 0.4286 - val_loss: 2.6615\n",
            "Epoch 71/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9294 - loss: 0.2850 - val_accuracy: 0.4286 - val_loss: 2.7356\n",
            "Epoch 72/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.1555 - val_accuracy: 0.4286 - val_loss: 2.7425\n",
            "Epoch 73/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: 0.2079 - val_accuracy: 0.3571 - val_loss: 2.7888\n",
            "Epoch 74/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9647 - loss: 0.1229 - val_accuracy: 0.3571 - val_loss: 2.8623\n",
            "Epoch 75/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9169 - loss: 0.1860 - val_accuracy: 0.4286 - val_loss: 2.8432\n",
            "Epoch 76/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9857 - loss: 0.0749 - val_accuracy: 0.4286 - val_loss: 2.8145\n",
            "Epoch 77/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9414 - loss: 0.1769 - val_accuracy: 0.4286 - val_loss: 2.8599\n",
            "Epoch 78/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9345 - loss: 0.1226 - val_accuracy: 0.3571 - val_loss: 2.9293\n",
            "Epoch 79/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9563 - loss: 0.1277 - val_accuracy: 0.3571 - val_loss: 3.0233\n",
            "Epoch 80/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 0.3571 - val_loss: 3.2016\n",
            "Epoch 81/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9933 - loss: 0.0944 - val_accuracy: 0.2857 - val_loss: 3.2929\n",
            "Epoch 82/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9413 - loss: 0.1544 - val_accuracy: 0.2857 - val_loss: 3.3144\n",
            "Epoch 83/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0669 - val_accuracy: 0.2857 - val_loss: 3.2711\n",
            "Epoch 84/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.1088 - val_accuracy: 0.2857 - val_loss: 3.2588\n",
            "Epoch 85/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0623 - val_accuracy: 0.2857 - val_loss: 3.3090\n",
            "Epoch 86/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9571 - loss: 0.1146 - val_accuracy: 0.2857 - val_loss: 3.3713\n",
            "Epoch 87/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0950 - val_accuracy: 0.3571 - val_loss: 3.2862\n",
            "Epoch 88/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9670 - loss: 0.1372 - val_accuracy: 0.2857 - val_loss: 3.2871\n",
            "Epoch 89/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 0.2857 - val_loss: 3.2677\n",
            "Epoch 90/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0499 - val_accuracy: 0.2857 - val_loss: 3.2972\n",
            "Epoch 91/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.1101 - val_accuracy: 0.3571 - val_loss: 3.3622\n",
            "Epoch 92/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9659 - loss: 0.1314 - val_accuracy: 0.3571 - val_loss: 3.3734\n",
            "Epoch 93/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - loss: 0.0690 - val_accuracy: 0.2857 - val_loss: 3.3407\n",
            "Epoch 94/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.1005 - val_accuracy: 0.2857 - val_loss: 3.3057\n",
            "Epoch 95/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8519 - loss: 0.2740 - val_accuracy: 0.2857 - val_loss: 3.1663\n",
            "Epoch 96/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9525 - loss: 0.1618 - val_accuracy: 0.3571 - val_loss: 3.2139\n",
            "Epoch 97/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0847 - val_accuracy: 0.3571 - val_loss: 3.2428\n",
            "Epoch 98/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9224 - loss: 0.2963 - val_accuracy: 0.2857 - val_loss: 3.1982\n",
            "Epoch 99/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.1037 - val_accuracy: 0.2857 - val_loss: 3.0400\n",
            "Epoch 100/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.1426 - val_accuracy: 0.3571 - val_loss: 2.9897\n",
            "Epoch 101/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9115 - loss: 0.2737 - val_accuracy: 0.3571 - val_loss: 3.0412\n",
            "Epoch 102/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0652 - val_accuracy: 0.3571 - val_loss: 3.0913\n",
            "Epoch 103/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1211 - val_accuracy: 0.3571 - val_loss: 3.1139\n",
            "Epoch 104/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0276 - val_accuracy: 0.3571 - val_loss: 3.1212\n",
            "Epoch 105/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0991 - val_accuracy: 0.3571 - val_loss: 3.1794\n",
            "Epoch 106/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0649 - val_accuracy: 0.3571 - val_loss: 3.1201\n",
            "Epoch 107/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.2199 - val_accuracy: 0.3571 - val_loss: 2.9632\n",
            "Epoch 108/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9508 - loss: 0.2088 - val_accuracy: 0.4286 - val_loss: 2.9482\n",
            "Epoch 109/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9801 - loss: 0.1098 - val_accuracy: 0.3571 - val_loss: 3.0440\n",
            "Epoch 110/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.1086 - val_accuracy: 0.3571 - val_loss: 3.0799\n",
            "Epoch 111/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0902 - val_accuracy: 0.3571 - val_loss: 3.0919\n",
            "Epoch 112/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.1442 - val_accuracy: 0.3571 - val_loss: 3.0379\n",
            "Epoch 113/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.1228 - val_accuracy: 0.3571 - val_loss: 3.0569\n",
            "Epoch 114/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9321 - loss: 0.2815 - val_accuracy: 0.3571 - val_loss: 3.1622\n",
            "Epoch 115/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.1174 - val_accuracy: 0.2857 - val_loss: 3.1962\n",
            "Epoch 116/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0674 - val_accuracy: 0.2857 - val_loss: 3.1469\n",
            "Epoch 117/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0509 - val_accuracy: 0.3571 - val_loss: 3.0551\n",
            "Epoch 118/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9933 - loss: 0.0469 - val_accuracy: 0.3571 - val_loss: 2.9908\n",
            "Epoch 119/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.1349 - val_accuracy: 0.4286 - val_loss: 3.0055\n",
            "Epoch 120/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.0739 - val_accuracy: 0.3571 - val_loss: 3.0856\n",
            "Epoch 121/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9441 - loss: 0.1266 - val_accuracy: 0.4286 - val_loss: 3.1404\n",
            "Epoch 122/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0992 - val_accuracy: 0.3571 - val_loss: 3.0972\n",
            "Epoch 123/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0444 - val_accuracy: 0.2857 - val_loss: 3.1318\n",
            "Epoch 124/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0183 - val_accuracy: 0.2857 - val_loss: 3.1206\n",
            "Epoch 125/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0290 - val_accuracy: 0.2857 - val_loss: 3.1291\n",
            "Epoch 126/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0480 - val_accuracy: 0.3571 - val_loss: 3.1365\n",
            "Epoch 127/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9761 - loss: 0.1168 - val_accuracy: 0.3571 - val_loss: 3.3459\n",
            "Epoch 128/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9664 - loss: 0.1552 - val_accuracy: 0.3571 - val_loss: 3.4098\n",
            "Epoch 129/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9582 - loss: 0.1042 - val_accuracy: 0.3571 - val_loss: 3.3470\n",
            "Epoch 130/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0737 - val_accuracy: 0.3571 - val_loss: 3.3118\n",
            "Epoch 131/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9480 - loss: 0.1073 - val_accuracy: 0.4286 - val_loss: 3.4128\n",
            "Epoch 132/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - loss: 0.1155 - val_accuracy: 0.4286 - val_loss: 3.4052\n",
            "Epoch 133/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 0.1249 - val_accuracy: 0.3571 - val_loss: 3.3163\n",
            "Epoch 134/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0801 - val_accuracy: 0.3571 - val_loss: 3.2663\n",
            "Epoch 135/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0685 - val_accuracy: 0.4286 - val_loss: 3.2458\n",
            "Epoch 136/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 0.0635 - val_accuracy: 0.3571 - val_loss: 3.2453\n",
            "Epoch 137/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8888 - loss: 0.2394 - val_accuracy: 0.2857 - val_loss: 3.2136\n",
            "Epoch 138/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0399 - val_accuracy: 0.3571 - val_loss: 3.1536\n",
            "Epoch 139/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9690 - loss: 0.0890 - val_accuracy: 0.3571 - val_loss: 3.0636\n",
            "Epoch 140/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0663 - val_accuracy: 0.3571 - val_loss: 2.9320\n",
            "Epoch 141/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0658 - val_accuracy: 0.5000 - val_loss: 2.8316\n",
            "Epoch 142/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0631 - val_accuracy: 0.5000 - val_loss: 2.8429\n",
            "Epoch 143/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0771 - val_accuracy: 0.5000 - val_loss: 2.8590\n",
            "Epoch 144/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0289 - val_accuracy: 0.5000 - val_loss: 2.8640\n",
            "Epoch 145/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0478 - val_accuracy: 0.4286 - val_loss: 2.9092\n",
            "Epoch 146/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0485 - val_accuracy: 0.4286 - val_loss: 2.9169\n",
            "Epoch 147/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0324 - val_accuracy: 0.3571 - val_loss: 3.0196\n",
            "Epoch 148/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0987 - val_accuracy: 0.4286 - val_loss: 2.9531\n",
            "Epoch 149/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0875 - val_accuracy: 0.5000 - val_loss: 2.9190\n",
            "Epoch 150/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0496 - val_accuracy: 0.5000 - val_loss: 2.8905\n",
            "Epoch 151/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - loss: 0.1137 - val_accuracy: 0.5000 - val_loss: 2.8663\n",
            "Epoch 152/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0435 - val_accuracy: 0.5000 - val_loss: 2.8703\n",
            "Epoch 153/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0318 - val_accuracy: 0.5000 - val_loss: 2.8706\n",
            "Epoch 154/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0860 - val_accuracy: 0.5000 - val_loss: 2.9252\n",
            "Epoch 155/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.5000 - val_loss: 2.9743\n",
            "Epoch 156/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0877 - val_accuracy: 0.5000 - val_loss: 3.0890\n",
            "Epoch 157/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0764 - val_accuracy: 0.5000 - val_loss: 3.1872\n",
            "Epoch 158/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9536 - loss: 0.0967 - val_accuracy: 0.5000 - val_loss: 3.1595\n",
            "Epoch 159/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.5000 - val_loss: 3.1804\n",
            "Epoch 160/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0375 - val_accuracy: 0.5000 - val_loss: 3.2148\n",
            "Epoch 161/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0481 - val_accuracy: 0.5000 - val_loss: 3.2694\n",
            "Epoch 162/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0422 - val_accuracy: 0.5000 - val_loss: 3.2448\n",
            "Epoch 163/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9558 - loss: 0.0766 - val_accuracy: 0.4286 - val_loss: 3.2019\n",
            "Epoch 164/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9730 - loss: 0.0742 - val_accuracy: 0.5000 - val_loss: 3.1810\n",
            "Epoch 165/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0363 - val_accuracy: 0.5000 - val_loss: 3.1999\n",
            "Epoch 166/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9796 - loss: 0.0481 - val_accuracy: 0.5000 - val_loss: 3.2660\n",
            "Epoch 167/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0280 - val_accuracy: 0.5000 - val_loss: 3.2875\n",
            "Epoch 168/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.5000 - val_loss: 3.3169\n",
            "Epoch 169/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0526 - val_accuracy: 0.4286 - val_loss: 3.3586\n",
            "Epoch 170/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0642 - val_accuracy: 0.4286 - val_loss: 3.4075\n",
            "Epoch 171/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0401 - val_accuracy: 0.4286 - val_loss: 3.3551\n",
            "Epoch 172/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0798 - val_accuracy: 0.5000 - val_loss: 3.2857\n",
            "Epoch 173/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0611 - val_accuracy: 0.4286 - val_loss: 3.3030\n",
            "Epoch 174/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0272 - val_accuracy: 0.4286 - val_loss: 3.4012\n",
            "Epoch 175/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.4286 - val_loss: 3.4661\n",
            "Epoch 176/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9591 - loss: 0.2105 - val_accuracy: 0.4286 - val_loss: 3.3340\n",
            "Epoch 177/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9511 - loss: 0.2216 - val_accuracy: 0.4286 - val_loss: 3.3253\n",
            "Epoch 178/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0428 - val_accuracy: 0.4286 - val_loss: 3.3913\n",
            "Epoch 179/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9614 - loss: 0.1013 - val_accuracy: 0.4286 - val_loss: 3.4083\n",
            "Epoch 180/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0407 - val_accuracy: 0.4286 - val_loss: 3.3963\n",
            "Epoch 181/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0373 - val_accuracy: 0.3571 - val_loss: 3.4707\n",
            "Epoch 182/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0515 - val_accuracy: 0.3571 - val_loss: 3.5063\n",
            "Epoch 183/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.3571 - val_loss: 3.5133\n",
            "Epoch 184/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9674 - loss: 0.0756 - val_accuracy: 0.3571 - val_loss: 3.5513\n",
            "Epoch 185/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0185 - val_accuracy: 0.3571 - val_loss: 3.5709\n",
            "Epoch 186/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0514 - val_accuracy: 0.4286 - val_loss: 3.5862\n",
            "Epoch 187/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.4286 - val_loss: 3.6286\n",
            "Epoch 188/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.3571 - val_loss: 3.6499\n",
            "Epoch 189/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0232 - val_accuracy: 0.3571 - val_loss: 3.6055\n",
            "Epoch 190/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 0.3571 - val_loss: 3.5602\n",
            "Epoch 191/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0464 - val_accuracy: 0.4286 - val_loss: 3.5284\n",
            "Epoch 192/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.4286 - val_loss: 3.5824\n",
            "Epoch 193/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.4286 - val_loss: 3.6147\n",
            "Epoch 194/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9433 - loss: 0.1962 - val_accuracy: 0.4286 - val_loss: 3.4266\n",
            "Epoch 195/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.1243 - val_accuracy: 0.4286 - val_loss: 3.3675\n",
            "Epoch 196/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0289 - val_accuracy: 0.4286 - val_loss: 3.3090\n",
            "Epoch 197/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9619 - loss: 0.0924 - val_accuracy: 0.4286 - val_loss: 3.2826\n",
            "Epoch 198/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.4286 - val_loss: 3.3066\n",
            "Epoch 199/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0280 - val_accuracy: 0.4286 - val_loss: 3.3251\n",
            "Epoch 200/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9780 - loss: 0.0936 - val_accuracy: 0.4286 - val_loss: 3.3518\n",
            "Epoch 201/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0453 - val_accuracy: 0.4286 - val_loss: 3.4637\n",
            "Epoch 202/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0750 - val_accuracy: 0.4286 - val_loss: 3.5942\n",
            "Epoch 203/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0279 - val_accuracy: 0.4286 - val_loss: 3.6121\n",
            "Epoch 204/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 0.4286 - val_loss: 3.5761\n",
            "Epoch 205/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - loss: 0.0451 - val_accuracy: 0.4286 - val_loss: 3.5597\n",
            "Epoch 206/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0303 - val_accuracy: 0.4286 - val_loss: 3.5195\n",
            "Epoch 207/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0591 - val_accuracy: 0.4286 - val_loss: 3.4807\n",
            "Epoch 208/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9786 - loss: 0.0454 - val_accuracy: 0.4286 - val_loss: 3.5074\n",
            "Epoch 209/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.3571 - val_loss: 3.5178\n",
            "Epoch 210/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0482 - val_accuracy: 0.3571 - val_loss: 3.5035\n",
            "Epoch 211/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0380 - val_accuracy: 0.3571 - val_loss: 3.5020\n",
            "Epoch 212/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9755 - loss: 0.0498 - val_accuracy: 0.5000 - val_loss: 3.4394\n",
            "Epoch 213/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0467 - val_accuracy: 0.5000 - val_loss: 3.3467\n",
            "Epoch 214/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0233 - val_accuracy: 0.5000 - val_loss: 3.3633\n",
            "Epoch 215/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0454 - val_accuracy: 0.5000 - val_loss: 3.3988\n",
            "Epoch 216/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0730 - val_accuracy: 0.5000 - val_loss: 3.3988\n",
            "Epoch 217/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5000 - val_loss: 3.4024\n",
            "Epoch 218/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0642 - val_accuracy: 0.5000 - val_loss: 3.3558\n",
            "Epoch 219/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0804 - val_accuracy: 0.5000 - val_loss: 3.4399\n",
            "Epoch 220/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0670 - val_accuracy: 0.5000 - val_loss: 3.5210\n",
            "Epoch 221/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.0769 - val_accuracy: 0.5000 - val_loss: 3.4051\n",
            "Epoch 222/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0401 - val_accuracy: 0.5000 - val_loss: 3.3701\n",
            "Epoch 223/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0327 - val_accuracy: 0.5000 - val_loss: 3.3969\n",
            "Epoch 224/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9861 - loss: 0.0160 - val_accuracy: 0.5000 - val_loss: 3.3897\n",
            "Epoch 225/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 0.5000 - val_loss: 3.3797\n",
            "Epoch 226/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0385 - val_accuracy: 0.5000 - val_loss: 3.3696\n",
            "Epoch 227/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.5000 - val_loss: 3.3509\n",
            "Epoch 228/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5000 - val_loss: 3.3525\n",
            "Epoch 229/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.5000 - val_loss: 3.3442\n",
            "Epoch 230/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0593 - val_accuracy: 0.5000 - val_loss: 3.3247\n",
            "Epoch 231/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 0.5000 - val_loss: 3.3215\n",
            "Epoch 232/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.4286 - val_loss: 3.3286\n",
            "Epoch 233/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9735 - loss: 0.1044 - val_accuracy: 0.5000 - val_loss: 3.1182\n",
            "Epoch 234/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0522 - val_accuracy: 0.4286 - val_loss: 3.0384\n",
            "Epoch 235/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0376 - val_accuracy: 0.3571 - val_loss: 3.0555\n",
            "Epoch 236/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0304 - val_accuracy: 0.4286 - val_loss: 2.9686\n",
            "Epoch 237/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9647 - loss: 0.0692 - val_accuracy: 0.4286 - val_loss: 3.1699\n",
            "Epoch 238/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0531 - val_accuracy: 0.4286 - val_loss: 3.1845\n",
            "Epoch 239/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9393 - loss: 0.2149 - val_accuracy: 0.4286 - val_loss: 3.2322\n",
            "Epoch 240/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.4286 - val_loss: 3.2813\n",
            "Epoch 241/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0470 - val_accuracy: 0.4286 - val_loss: 3.2242\n",
            "Epoch 242/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0305 - val_accuracy: 0.4286 - val_loss: 3.1803\n",
            "Epoch 243/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.0571 - val_accuracy: 0.4286 - val_loss: 3.1846\n",
            "Epoch 244/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0415 - val_accuracy: 0.4286 - val_loss: 3.2309\n",
            "Epoch 245/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9664 - loss: 0.0530 - val_accuracy: 0.4286 - val_loss: 3.2001\n",
            "Epoch 246/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0283 - val_accuracy: 0.4286 - val_loss: 3.1634\n",
            "Epoch 247/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0570 - val_accuracy: 0.4286 - val_loss: 3.1378\n",
            "Epoch 248/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0349 - val_accuracy: 0.4286 - val_loss: 3.0885\n",
            "Epoch 249/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - loss: 0.0487 - val_accuracy: 0.4286 - val_loss: 3.0396\n",
            "Epoch 250/250\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.0884 - val_accuracy: 0.4286 - val_loss: 3.0626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('ds_chatbot_model.h5')\n",
        "pickle.dump({\n",
        "    'words': words,\n",
        "    'classes': classes,\n",
        "    'history': history.history\n",
        "}, open('ds_chatbot_data.pkl', 'wb'))\n",
        "\n",
        "print(\"Model saved to 'ds_chatbot_model.h5' and data saved to 'chatbot_data.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y11RJRCOvHP",
        "outputId": "5282b399-be69-4982-c7f8-86c23a848262"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to 'ds_chatbot_model.h5' and data saved to 'chatbot_data.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load job_intents.json\n",
        "# ---------------------------\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    intents = json.load(f)"
      ],
      "metadata": {
        "id": "AfO4s8PAOvEq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------\n",
        "# 2. Extract unique classes (tags)\n",
        "# ---------------------------\n",
        "classes = []\n",
        "\n",
        "for intent in intents.get(\"intents\", []):\n",
        "    tag = intent.get(\"tag\")\n",
        "    if tag and tag not in classes:\n",
        "        classes.append(tag)\n",
        "\n",
        "# Sort classes\n",
        "classes = sorted(classes)\n",
        "\n",
        "print(\"Total classes found:\", len(classes))\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAXG735IOvB6",
        "outputId": "b1086465-fd19-4540-fb22-d32662d16f4d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total classes found: 20\n",
            "['career_after_graduation', 'career_confusion', 'career_gap', 'career_motivation', 'career_switch', 'confidence_building', 'data_analyst_roadmap', 'data_science_roadmap', 'first_job_fear', 'goodbye', 'greeting', 'internship_guidance', 'interview_preparation', 'job_vs_higher_studies', 'linkedin_profile', 'project_importance', 'resume_tips', 'salary_expectation', 'skills_for_freshers', 'soft_skills']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 3. Save classes.pkl\n",
        "# ---------------------------\n",
        "with open(\"classes.pkl\", \"wb\") as f:\n",
        "    pickle.dump(classes, f)\n",
        "\n",
        "print(\"\\nclasses.pkl file successfully created!\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih224NaUQHE5",
        "outputId": "e6744aca-757b-4c12-c962-77a0124ebda4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "classes.pkl file successfully created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required NLTK models (first time only)\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# --------------------------------------\n",
        "# 1. Load job_intents.json\n",
        "# --------------------------------------\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    intents = json.load(f)\n",
        "\n",
        "# --------------------------------------\n",
        "# 2. Preprocessing setup\n",
        "# --------------------------------------\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "ignore_words = ['?', '!', '.', ',']\n",
        "\n",
        "words = []        # vocabulary list\n",
        "documents = []    # (pattern, tag) pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYqjp4EJQKxp",
        "outputId": "4f41bd2a-18a5-4fa9-fe89-fe49ef463772"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Tokenize, lemmatize & collect words\n",
        "# --------------------------------------\n",
        "for intent in intents[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        tokens = word_tokenize(pattern)               # tokenize\n",
        "        words.extend(tokens)                          # add tokens\n",
        "        documents.append((tokens, intent[\"tag\"]))     # store structure\n",
        "\n",
        "# --------------------------------------\n",
        "# 4. Clean words → lower, lemmatize, remove symbols\n",
        "# --------------------------------------\n",
        "words = [lemmatizer.lemmatize(w.lower())\n",
        "         for w in words\n",
        "         if w not in ignore_words]\n",
        "\n",
        "# unique + sorted\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "print(\"Total unique words:\", len(words))\n",
        "print(words[:50])   # first 50 words preview\n",
        "\n",
        "# --------------------------------------\n",
        "# 5. Save words.pkl\n",
        "# --------------------------------------\n",
        "with open(\"words.pkl\", \"wb\") as f:\n",
        "    pickle.dump(words, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IILhTEpwQTnZ",
        "outputId": "ac1f2dea-6328-4a16-a1ed-1c39cb5be50a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words: 100\n",
            "['a', 'about', 'after', 'am', 'analysis', 'analyst', 'anyone', 'are', 'become', 'build', 'bye', 'career', 'change', 'choose', 'college', 'confidence', 'confused', 'crack', 'data', 'day', 'degree', 'demotivated', 'do', 'expect', 'expected', 'explain', 'fear', 'feel', 'find', 'first', 'for', 'fresher', 'gap', 'get', 'good', 'graduation', 'guidance', 'hello', 'hey', 'hi', 'higher', 'how', 'i', 'importance', 'important', 'improve', 'in', 'internship', 'interview', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iy9-TeeOQYJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}